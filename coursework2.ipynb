{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework 1 - Mathematics for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Due: 25/03/2025\n",
    "\n",
    "## CID: 02021144\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Quick questions [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1:\n",
    "\n",
    "The bias correction terms in the Adam algorithm are useful during the initial iterations of the algorithm. We initialise both first and second moments to 0 and update them as $\\text{moment} = \\beta \\cdot \\text{moment} + (1- \\beta){new \\, moment}$ for $\\beta$ < 1, usually = 0.9 to 0.99. We can see that in the initial stages, the effect of the first few incoming moments are being scaled down by the $(1- \\beta)$ factor. Therefore the bias correction term divides the moments by a factor $(1- \\beta^t)$ to mitigate this and help the algorithm move quicker in the initial stages. As the number of iterations $t$ grows, the bias correction factor converges to 1, thereby becoming insignificant as the algorithm settles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2:\n",
    "\n",
    "Stochastic Gradient Descent (SGD) is an extension of gradient descent, designed to reduce computational cost when training dataset size is too large for GPU or system memory. It achieves this by approximating the gradient of the loss function with smaller minibatches. This reduces the number of gradient calculations required per iterative descent step and the size of these minibatches is selected such that they fit within the memory requirements of the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3:\n",
    "\n",
    "The idea of Kaiming initializtion is to initialise the weights such that input signals are not exponentially magnified or reduced as they are propagated through the network layers. This can be mathematically stated as $Var(y_L) = Var(y_1)$, meaning the variance of the last layer is the same as variance of the first for a newly initialised network.\n",
    "\n",
    "In the simplest case we can look at forward propagation for a feed forward Relu network. Let $y_l = W_lx_l$ for the equation of the $l$'th indexed layer with no bias. $y_l$ is composed of $n_l$ multiplications $w_lx_l$ for row vector $w_l$ and column vector $x_l$. Assume elements of $y_l$, $w_l$ and $x_l$ are independent and distributed symmetrically around 0.\n",
    "$$\n",
    "Var(y_l) = n_l \\, Var(w_lx_l) = n_l \\, \\mathbb{E}[w_l^2]\\mathbb{E}[x_l^2] = n_l \\, Var(w_l)\\mathbb{E}[x_l^2]\n",
    "$$\n",
    "\n",
    "Now we can use the Relu activation to rewrite $x_l$ in terms of $y_{l-1}$:\n",
    "$$\n",
    "\\mathbb{E}[x_l^2] = \\mathbb{E}[Relu(y_{l-1})^2] = \\mathbb{E}[(y_{l-1} \\cdot \\mathbb{1}(y_{l-1} > 0))^2] = \\mathbb{E}[y_{l-1}^2 \\cdot \\mathbb{1}(y_{l-1} > 0)] = \\frac{1}{2} \\mathbb{E}[y_{l-1}^2] = \\frac{1}{2} Var(y_{l-1})\n",
    "$$\n",
    "\n",
    "Now we can substitute this back into the variance equation and expand it from layer 1 to L:\n",
    "$$\n",
    "Var(y_l) = \\frac{1}{2} n_l \\, Var(w_l) \\, Var(y_{l-1}) \\implies Var(y_L) = \\left( \\prod_{l=2}^{L} \\frac{1}{2} n_l \\, Var(w_l) \\right) \\, Var(y_{1})\n",
    "$$\n",
    "\n",
    "Now returning to our original goal, if we want $Var(y_L) = Var(y_1)$, requiring $\\frac{1}{2} n_l \\, Var(w_l) = 1 \\quad \\forall l > 0$ is sufficient. If we let $w_l$ follow a gaussian distribution and $Var(w_l) = \\frac{2}{n_l}$, then $w_l \\sim N(0, \\frac{2}{n_l})$ fulfils this requirement and $\\sigma_l = \\sqrt{\\frac{2}{n_l}}$.\n",
    "\n",
    "Therefore the $\\sqrt{2}$ factor can be traced back to taking the second moment under Relu from layer to layer. The $\\frac{1}{2}$ factor comes out of the fact that $Relu(x)$ is zero for $x < 0$ and all initialization elements are symmetrically distributed around 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4:\n",
    "\n",
    "Theorem 4.2 uses the Lipschitz continuity for the proof for Lemma 4.4:\n",
    "$$\n",
    "|h(x) - g(x)| = |g(u_s) - g(x)| \\leq \\rho \\|u_s - x\\|_2 \\leq \\epsilon\n",
    "$$\n",
    "Where $u_s$ is defined as the corner of the side length $\\frac{1}{k}$ half open cube that contains $x$. The $\\rho$ Lipschitz continuity of $g$ lets us perform this bound and bound again with $\\epsilon$ by construction of $k$.\n",
    "\n",
    "This lemma is used when considering the following integral from the proof for Theorem 4.2:\n",
    "$$\n",
    "\\int_{[0, 1)^d} |f(x) - g(x)| \\, dx = \\int_{[0, 1)^d} |f(x) - h(x)| + |h(x) - g(x)| \\, dx \\leq \\int_{[0, 1)^d} |f(x) - h(x)| + \\epsilon\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "***\n",
    "\n",
    "## Exercise 2: [6 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Question 1 [2 points]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proving $\\mathcal{F}_{cos,d}$ is a universal approximator:\n",
    "\n",
    "1. Each $f \\in \\mathcal{F}_{cos,d}$ takes the form $\\sum_{i=1}^N a_i \\cos(\\langle c_i, x \\rangle + e_i)$:\n",
    "   - cos is continuous\n",
    "   - a scaled continuous function is continuous\n",
    "   - a finite sum of continuous functions is continuous\n",
    "   - Therefore every $f \\in \\mathcal{F}_{cos,d}$ is continuous\n",
    "3. For every $x$, $\\cos(0^Tx) = 1 \\neq 0$\n",
    "4. For every $x \\neq x'$, let $f(a) = cos((a-x)^T(x'-x)/\\|x'-x\\|_2^2)$, $f(x) = cos(0) \\neq cos(1) = f(x')$. Therefore $\\mathcal{F}_{cos,d}$ separates points.\n",
    "5. Proving $\\mathcal{F}_{cos,d}$ is closed under multiplication and vector space operations:\n",
    "\n",
    "Let $f(x) = \\sum_{i=1}^N a_i \\cos(\\langle c_i, x \\rangle + e_i)$ and $g(x) = \\sum_{j=1}^M b_j \\cos(\\langle d_j, x \\rangle + f_j)$.\n",
    "\n",
    "First under vector space operations:\n",
    "$$\n",
    "\\alpha f(x) + \\beta g(x) \n",
    "= \\sum_{i=1}^N \\alpha a_i \\cos(\\langle c_i, x \\rangle + e_i) + \\sum_{j=1}^M \\beta b_j \\cos(\\langle d_j, x \\rangle + f_j)\n",
    "= \\sum_{k=1}^L\\alpha s_k \\cos(\\langle t_k, x \\rangle + u_k) = h(x) \\in \\mathcal{F}_{cos,d}\n",
    "$$\n",
    "where:\n",
    "- $L = N + M$\n",
    "- $(s_k) = (\\alpha a_1, ...,\\alpha a_N, \\beta b_1, ..., \\beta b_M)$\n",
    "- $(t_k) = (\\alpha c_1, ...,\\alpha c_N, \\beta d_1, ..., \\beta d_M)$\n",
    "- $(u_k) = (\\alpha e_1, ...,\\alpha e_N, \\beta f_1, ..., \\beta f_M)$\n",
    "\n",
    "So $\\mathcal{F}_{cos,d}$ is closed under vector space operations.\n",
    "\n",
    "Now under multiplication:\n",
    "$$\n",
    "f(x) \\cdot g(x)\n",
    "= \\left( \\sum_{i=1}^N a_i \\cos(\\langle c_i, x \\rangle + e_i) \\right) \\left( \\sum_{j=1}^M b_j \\cos(\\langle d_j, x \\rangle + f_j) \\right)\n",
    "= \\sum_{i=1}^N \\sum_{j=1}^M a_i b_j \\cos(\\langle c_i, x \\rangle + e_i) \\cos(\\langle d_j, x \\rangle + f_j)\n",
    "$$\n",
    "\n",
    "Now using $\\cos A \\cos B = \\frac{1}{2}(\\cos(A+B) + \\cos(A-B))$\n",
    "$$\n",
    "= \\sum_{i=1}^N \\sum_{j=1}^M \\frac{a_i b_j}{2} (\\cos(\\langle (c_i + d_j), x \\rangle + (e_i + f_j)) + \\cos(\\langle (c_i - d_j), x \\rangle + (e_i - f_j)))\n",
    "$$\n",
    "$$\n",
    "= \\sum_{i=1}^N \\sum_{j=1}^M k_{ij} (m_{ij}(x) + n_{ij}(x))\n",
    "= \\sum_{i=1}^N \\sum_{j=1}^M k_{ij} p_{ij}(x) \n",
    "= \\sum_{i=1}^N q_{i}(x) = r(x) \n",
    "\\in \\mathcal{F}_{cos,d}\n",
    "$$\n",
    "\n",
    "Where functions $m_{ij}, n_{ij}, p_{ij}, q_i \\in \\mathcal{F}_{cos,d}$ with the following definitions\n",
    "- $k_{ij} = \\frac{a_i b_j}{2}$\n",
    "- $m_{ij}(x) = \\cos(\\langle (c_i + d_j), x \\rangle + (e_i + f_j))$\n",
    "- $n_{ij}(x) = \\cos(\\langle (c_i - d_j), x \\rangle + (e_i - f_j))$\n",
    "- $p_{ij}(x) = m_{ij}(x) + n_{ij}(x)$\n",
    "- $q_{i}(x) = \\sum_{j=1}^M k_{ij} p_{ij}(x)$\n",
    "\n",
    "The last line uses closure under vector operations to reduce the product and show multiplication is also closed.\n",
    "\n",
    "These four conditions are enough to satisfy Theorem 4.7 (Stone-Weierstrass) which concludes that $\\mathcal{F}_{cos,d}$ is a universal approximator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Question 2 [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original model had equation:\n",
    "$$\n",
    "f(x) = A_2 \\sigma(A_1 x + b_1) = \\sum_{i=1}^w (A_w)_i\\sigma((A_1)_i x + (b_1)_i)\n",
    "$$\n",
    "\n",
    "We will use a $w$ hidden layer network instead to accumulate this sum. We only need width $d+3$. Define the following:\n",
    "$$\n",
    "M_1 =\n",
    "\\left[\n",
    "\\begin{array}{ccc}\n",
    "\\ddots &  &  \\\\\n",
    "  & I_d &  \\\\\n",
    "  &   & \\ddots \\\\ \\hline\n",
    "\\dots & (A_1)_1 & \\dots \\\\ \\hline\n",
    "\\dots & 0 & \\dots \\\\\n",
    "\\dots & 0 & \\dots\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\qquad\n",
    "M_l =\n",
    "\\left[\n",
    "\\begin{array}{ccc|c|cc}\n",
    "\\ddots &  &  & \\vdots & \\vdots & \\vdots \\\\\n",
    "  & I_d &  & 0 & 0 & 0 \\\\\n",
    "  &   & \\ddots & \\vdots & \\vdots & \\vdots \\\\ \\hline\n",
    "\\dots & (A_1)_l & \\dots & 0 & 0 & 0 \\\\ \\hline\n",
    "\\dots & 0 & \\dots & (A_2)_{l-1} & 1 & -1 \\\\\n",
    "\\dots & 0 & \\dots & -(A_2)_{l-1} & -1 & 1\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\text{ for } 2 \\leq l \\leq w\n",
    "\\qquad\n",
    "B_l = \n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "\\vdots \\\\\n",
    "0 \\\\\n",
    "\\vdots \\\\ \\hline\n",
    "(b_1)_i \\\\ \\hline\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\text{ for } 1 \\leq l \\leq w\n",
    "\\qquad\n",
    "M_{w+1} =\n",
    "\\left[\n",
    "\\begin{array}{ccc|c|cc}\n",
    "\\dots & 0 & \\dots & (A_2)_w & 1 & -1\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "for\n",
    "- $M_1 \\in \\mathbb{R}^{(d+3) \\times d}$\n",
    "- $M_l \\in \\mathbb{R}^{(d+3) \\times (d+3)}$ for $2 \\leq l \\leq w$\n",
    "- $M_{w+1} \\in \\mathbb{R}^{(d+3) \\times 1}$\n",
    "- $B_1 \\in \\mathbb{R}^{d+3}$ for $1 \\leq l \\leq w$\n",
    "\n",
    "Now define:\n",
    "- $c_i = \\sigma((A_1)_i x + (b_1)_i)$\n",
    "- $s_l = \\sum_{i=1}^l (A_2)_i c_i$\n",
    "\n",
    "It is clear that $s_w = f(x)$. $s_w$ is the variable that we are going to accumulate through the layers.\n",
    "\n",
    "The first layer can take the original input $x$ and we have $x_1 = \\sigma(M_1x + B_1)$.\n",
    "\n",
    "We can see how each layer evaluates:\n",
    "$$\n",
    "\\sigma(M_{l+1}x_l + B_{l+1}) =\n",
    "\\sigma \\left(\n",
    "\\left[ \\begin{array}{ccc|c|cc} \\ddots &  &  & \\vdots & \\vdots & \\vdots \\\\ & I_d &  & 0 & 0 & 0 \\\\ &   & \\ddots & \\vdots & \\vdots & \\vdots \\\\ \\hline \\dots & (A_1)_{l+1} & \\dots & 0 & 0 & 0 \\\\ \\hline \\dots & 0 & \\dots & (A_2)_{l} & 1 & -1 \\\\ \\dots & 0 & \\dots & -(A_2)_{l} & -1 & 1 \\end{array} \\right]\n",
    "\\left[ \\begin{array}{c} \\vdots \\\\ x \\\\ \\vdots \\\\ \\hline c_{l} \\\\ \\hline \\sigma(s_{l-1}) \\\\ \\sigma(-s_{l-1}) \\\\ \\end{array} \\right]\n",
    "+\n",
    "\\left[ \\begin{array}{c} \\vdots \\\\ 0 \\\\ \\vdots \\\\ \\hline (b_1)_{l+1} \\\\ \\hline 0 \\\\ 0 \\\\ \\end{array} \\right]\n",
    "\\right)\n",
    "= \\sigma \\left( \\left[ \\begin{array}{c} \\vdots \\\\ x \\\\ \\vdots \\\\ \\hline (A_1)_{l+1} x + (b_1)_{l+1} \\\\ \\hline (A_2)_{l}c_l + \\sigma(s_{l-1}) - \\sigma(-s_{l-1}) \\\\ -(A_2)_{l}c_l - \\sigma(s_{l-1}) + \\sigma(-s_{l-1}) \\\\ \\end{array} \\right] \\right)\n",
    "= \\sigma \\left( \\left[ \\begin{array}{c} \\vdots \\\\ x \\\\ \\vdots \\\\ \\hline (A_1)_{l+1} x + (b_1)_{l+1} \\\\ \\hline (A_2)_{l}c_l + s_{l-1} \\\\ -((A_2)_{l}c_l + s_{l-1}) \\\\ \\end{array} \\right] \\right)\n",
    "= \\left[ \\begin{array}{c} \\vdots \\\\ x \\\\ \\vdots \\\\ \\hline c_{l+1} \\\\ \\hline \\sigma(s_{l}) \\\\ \\sigma(-s_{l}) \\\\ \\end{array} \\right]\n",
    "= x_{l+1}\n",
    "$$\n",
    "\n",
    "Which uses $\\sigma(\\alpha) - \\sigma(-\\alpha) = \\alpha$ and the fact that $\\sigma(x) = x$ because $x \\in \\mathbb{R}^{[0,1]}$. \n",
    "\n",
    "Using this can observe the state of $x_l$ as it goes through the $w$ hidden layers:\n",
    "$$\n",
    "x_1 = \\left[ \\begin{array}{c} \\vdots \\\\ x \\\\ \\vdots \\\\ \\hline c_1 \\\\ \\hline 0 \\\\ 0 \\\\ \\end{array} \\right]\n",
    "\\qquad\n",
    "x_2 = \\left[ \\begin{array}{c} \\vdots \\\\ x \\\\ \\vdots \\\\ \\hline c_2 \\\\ \\hline \\sigma(s_1) \\\\ \\sigma(-s_1) \\\\ \\end{array} \\right]\n",
    "\\qquad\n",
    "x_3 = \\left[ \\begin{array}{c} \\vdots \\\\ x \\\\ \\vdots \\\\ \\hline c_3 \\\\ \\hline \\sigma(s_2) \\\\ \\sigma(-s_2) \\\\ \\end{array} \\right]\n",
    "\\qquad\n",
    "\\dots\n",
    "\\qquad\n",
    "x_w = \\left[ \\begin{array}{c} \\vdots \\\\ x \\\\ \\vdots \\\\ \\hline c_w \\\\ \\hline \\sigma(s_{w-1}) \\\\ \\sigma(-s_{w-1}) \\\\ \\end{array} \\right]\n",
    "$$\n",
    "\n",
    "It is important to note how we calculate and store the positive and negative of $s_l$. If we stored only $s_l$ it could get wiped out by the Relu. Therefore we store both and one of them will be zero each time as we go through each Relu.\n",
    "\n",
    "Finally the output layer evaluates to:\n",
    "$$\n",
    "M_{w+1}x_w\n",
    "= \\left[ \\begin{array}{ccc|c|cc} \\dots & 0 & \\dots & (A_2)_w & 1 & -1 \\end{array} \\right]\n",
    "\\left[ \\begin{array}{c} \\vdots \\\\ x \\\\ \\vdots \\\\ \\hline c_w \\\\ \\hline \\sigma(s_{w-1}) \\\\ \\sigma(-s_{w-1}) \\\\ \\end{array} \\right]\n",
    "= (A_2)_w c_w + \\sigma(s_{w-1}) - \\sigma(-s_{w-1}) = (A_2)_w c_w + s_{w-1} = s_w = f(x)\n",
    "$$\n",
    "... as desired.\n",
    "\n",
    "This uses width $d+3$. In order to fulfil width $2d+3 > d+3$, we can pad all $M$ and $B$ matricies with zeros and achieve the same result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Question 3 [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot $a$, the training loss steadily decreases. Starting at just under 0.7, the first 200 epochs loss falls faster than the last 300 but both are relatively slow. After 500 epochs the loss is still relatively high at just above 0.1 and the algorithm evidently has more training left to do. The loss curve is veery smooth with no spikes or oscillations. These factors indicate the learning rate is too small and parameter updates are too conservative, resulting in slow model convergence. To improve this convergence, we would increase the learning rate and let the model take larger parameter update steps as this would help the loss fall faster.\n",
    "\n",
    "In plot $b$, training loss starts high and exhibits large oscillations throughout training. The first 80 epochs show potential convergence but then the loss rises and never meaningfully converges. From epoch 100 onwards, the base loss is around 0.3 with frequent spikes to almost 0.6. This behaviour is indicative of a learning rate that is too high. We can clearly see the model constantly overshoot itself in the loss landscape and jump around without converging smoothly to the minimum. To improve this convergence we would decrease the learning rate so that the model converges more carefully. We might also increase batch size if we can as this would result in less noisy parameter updates.\n",
    "\n",
    "In plot $c$, the loss starts at 0.6 and falls quickly to 0.1 within the first 50 epochs. For the remaining 450 epochs, the loss slowly and consistently decreases with occasional small oscillations. By the end of 500 epochs the model seems to have converged at a near zero loss which is exactly as desired. The model convergence was stable and efficient compared to the other two plots, indicative of a well chosen learning rate. This convergence is already quite good and there is nothing obvious we might to do improve it. Out of the box suggestions might include using a scheduler to scale down learning rate over a number of epochs. We could also use momentum for perhaps even faster and better convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "## Exercise 3: Implementation [13 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T18:07:16.534996Z",
     "start_time": "2025-03-22T18:07:13.047544Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Image classification [4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 1 [0.5 point]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Download the dataset from\n",
    "https://chaladze.com/l5/img/Linnaeus%205%2032X32.rar\n",
    "and uncompress the .rar dataset to a folder named \"Linnaeus_5_32X32\" in the current directory.\n",
    "This folder contains a subfolder \"Linnaeus 5 32X32\", which contains a test and a train folder with the images of the dataset in 5 different classes: berry, bird, dog, flower, other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T18:10:54.823668Z",
     "start_time": "2025-03-22T18:10:54.781077Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# trainset = torchvision.datasets.ImageFolder(root=\"Linnaeus_5_32X32\\\\Linnaeus 5 32X32\\\\train\", transform=transform)\n",
    "# alternative file paths for Unix systems\n",
    "trainset = torchvision.datasets.ImageFolder(root=\"Linnaeus_5_32X32/Linnaeus 5 32X32/train\", transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# testset = torchvision.datasets.ImageFolder(root=\"Linnaeus_5_32X32\\\\Linnaeus 5 32X32\\\\test\", transform=transform)\n",
    "testset = torchvision.datasets.ImageFolder(root=\"Linnaeus_5_32X32/Linnaeus 5 32X32/test\", transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False,)\n",
    "\n",
    "classes = ('berry', 'bird', 'dog', 'flower', 'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T12:35:51.241733Z",
     "start_time": "2025-03-22T12:35:36.763214Z"
    }
   },
   "outputs": [],
   "source": [
    "# dictionary to save one image per class to display\n",
    "to_display = {cls: None for cls in trainset.classes}\n",
    "\n",
    "# reverse of class to idx\n",
    "idx_to_class = {i: c for c, i in trainset.class_to_idx.items()}\n",
    "\n",
    "i = 0\n",
    "# loop through training dataset\n",
    "for img, label in trainset:\n",
    "    # if we find a class that we have not seen before\n",
    "    if to_display[idx_to_class[label]] is None:\n",
    "        # save the image\n",
    "        to_display[idx_to_class[label]] = img\n",
    "        i += 1\n",
    "    # if we have counted all classes, break loop\n",
    "    if i >= len(trainset.classes):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reverse of transform for displaying\n",
    "def rescale(img):\n",
    "    return (img + 1) / 2\n",
    "\n",
    "# plot images for each class\n",
    "fig, axs = plt.subplots(1, len(trainset.classes), figsize=(15, 3))\n",
    "for i in range(len(trainset.classes)):\n",
    "    cls = trainset.classes[i]\n",
    "    axs[i].imshow(rescale(to_display[cls].numpy()).transpose(1, 2, 0))\n",
    "    axs[i].axis('off')\n",
    "    axs[i].set_title(cls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 [0.5 point]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
    ")]\n",
    "```\n",
    "The above transform has two stages.\n",
    "1. Take an input image (either a PIL image or numpy array of shape (H, W, C)) and converts it into a torch tensor of shape (C, H, W) whilst scaling from [0, 255] to [0, 1]. \n",
    "2. normalise transform applies channel-wise normalisation for each pixel. It computes $x_{norm} = \\frac{x-0.5}{0.5}$. This transforms the pixel ranges from [0, 1] to [-1, 1].\n",
    "\n",
    "Converting to pytorch tensors is needed so that we can carry out pytorch operations e.g. feed through models etc. Scaling and normalising the pixel values to be centred around zero is useful so that all numbers are in a small controlled range and avoid exploding or vanishing values/gradients during training which leads to more efficient convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 3 [1 point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T18:10:19.337759Z",
     "start_time": "2025-03-22T18:10:19.318787Z"
    }
   },
   "outputs": [],
   "source": [
    "class myCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myCNN, self).__init__()\n",
    "        # feature extraction layers. 6 3x3 convolutional layers with 3 maxpooling layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.mp1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.mp2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.mp3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # fully connected layers 4096 -> 512 -> 64 -> 5\n",
    "        self.fc1 = nn.Linear(in_features=4096, out_features=512)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=64)\n",
    "        self.fc3 = nn.Linear(in_features=64, out_features=5)\n",
    "\n",
    "        # relu activation\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # cnn\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.mp1(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.mp2(x)\n",
    "        x = self.relu(self.conv5(x))\n",
    "        x = self.relu(self.conv6(x))\n",
    "        x = self.mp3(x)\n",
    "\n",
    "        # flatten\n",
    "        x = x.view(-1, 4096)\n",
    "\n",
    "        # fcn\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 4 [0.5 point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T12:35:57.193430Z",
     "start_time": "2025-03-22T12:35:56.739542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 32, 32]             896\n",
      "              ReLU-2           [-1, 32, 32, 32]               0\n",
      "            Conv2d-3           [-1, 64, 32, 32]          18,496\n",
      "              ReLU-4           [-1, 64, 32, 32]               0\n",
      "         MaxPool2d-5           [-1, 64, 16, 16]               0\n",
      "            Conv2d-6          [-1, 128, 16, 16]          73,856\n",
      "              ReLU-7          [-1, 128, 16, 16]               0\n",
      "            Conv2d-8          [-1, 128, 16, 16]         147,584\n",
      "              ReLU-9          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-10            [-1, 128, 8, 8]               0\n",
      "           Conv2d-11            [-1, 256, 8, 8]         295,168\n",
      "             ReLU-12            [-1, 256, 8, 8]               0\n",
      "           Conv2d-13            [-1, 256, 8, 8]         590,080\n",
      "             ReLU-14            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-15            [-1, 256, 4, 4]               0\n",
      "           Linear-16                  [-1, 512]       2,097,664\n",
      "             ReLU-17                  [-1, 512]               0\n",
      "           Linear-18                   [-1, 64]          32,832\n",
      "             ReLU-19                   [-1, 64]               0\n",
      "           Linear-20                    [-1, 5]             325\n",
      "================================================================\n",
      "Total params: 3,256,901\n",
      "Trainable params: 3,256,901\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 3.23\n",
      "Params size (MB): 12.42\n",
      "Estimated Total Size (MB): 15.66\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(myCNN().cuda(), (3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 5 [0.5 point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T12:35:59.579766Z",
     "start_time": "2025-03-22T12:35:59.567490Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(myCNN, nr_epochs, optimizer ,criterion, trainloader):\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    criterion.to(device)\n",
    "\n",
    "    # loop for number of epochs\n",
    "    for epoch in range(nr_epochs):\n",
    "        # iterate training loader\n",
    "        for i, (inputs, labels) in enumerate(trainloader):\n",
    "            # zero gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # move to device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # process inputs\n",
    "            outputs = myCNN(inputs)\n",
    "            # calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # backpropagate\n",
    "            loss.backward()\n",
    "\n",
    "            # move back from cpu to save memory\n",
    "            inputs = inputs.cpu()\n",
    "            labels = labels.cpu()\n",
    "\n",
    "            # update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # print loss every 10 batches\n",
    "            if i % 10 == 0:\n",
    "                print('Epoch [{}/{}], Batch {}, Loss: {:.4f}'.format(epoch+1, nr_epochs, i, loss.item()))\n",
    "\n",
    "        # print loss value for epoch\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, nr_epochs, loss.item()))\n",
    "\n",
    "    model.cpu()\n",
    "    criterion.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 6 [0.5 point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T23:13:45.523839600Z",
     "start_time": "2025-03-17T21:03:57.267438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30] Batch 0, Loss: 1.6108\n",
      "Epoch [1/30] Batch 10, Loss: 1.5924\n",
      "Epoch [1/30] Batch 20, Loss: 1.5868\n",
      "Epoch [1/30] Batch 30, Loss: 1.5445\n",
      "Epoch [1/30] Batch 40, Loss: 1.5957\n",
      "Epoch [1/30], Loss: 1.4787\n",
      "Epoch [2/30] Batch 0, Loss: 1.4123\n",
      "Epoch [2/30] Batch 10, Loss: 1.4187\n",
      "Epoch [2/30] Batch 20, Loss: 1.4966\n",
      "Epoch [2/30] Batch 30, Loss: 1.4160\n",
      "Epoch [2/30] Batch 40, Loss: 1.4006\n",
      "Epoch [2/30], Loss: 1.2692\n",
      "Epoch [3/30] Batch 0, Loss: 1.2630\n",
      "Epoch [3/30] Batch 10, Loss: 1.3869\n",
      "Epoch [3/30] Batch 20, Loss: 1.2470\n",
      "Epoch [3/30] Batch 30, Loss: 1.3426\n",
      "Epoch [3/30] Batch 40, Loss: 1.2779\n",
      "Epoch [3/30], Loss: 1.3316\n",
      "Epoch [4/30] Batch 0, Loss: 1.3105\n",
      "Epoch [4/30] Batch 10, Loss: 1.2825\n",
      "Epoch [4/30] Batch 20, Loss: 1.2103\n",
      "Epoch [4/30] Batch 30, Loss: 1.2415\n",
      "Epoch [4/30] Batch 40, Loss: 1.2308\n",
      "Epoch [4/30], Loss: 1.2679\n",
      "Epoch [5/30] Batch 0, Loss: 1.2618\n",
      "Epoch [5/30] Batch 10, Loss: 1.1717\n",
      "Epoch [5/30] Batch 20, Loss: 1.1005\n",
      "Epoch [5/30] Batch 30, Loss: 1.2554\n",
      "Epoch [5/30] Batch 40, Loss: 1.1253\n",
      "Epoch [5/30], Loss: 1.4433\n",
      "Epoch [6/30] Batch 0, Loss: 1.1016\n",
      "Epoch [6/30] Batch 10, Loss: 1.1130\n",
      "Epoch [6/30] Batch 20, Loss: 1.3584\n",
      "Epoch [6/30] Batch 30, Loss: 1.1009\n",
      "Epoch [6/30] Batch 40, Loss: 1.1989\n",
      "Epoch [6/30], Loss: 1.1779\n",
      "Epoch [7/30] Batch 0, Loss: 1.2485\n",
      "Epoch [7/30] Batch 10, Loss: 1.0203\n",
      "Epoch [7/30] Batch 20, Loss: 1.1858\n",
      "Epoch [7/30] Batch 30, Loss: 1.0879\n",
      "Epoch [7/30] Batch 40, Loss: 1.1520\n",
      "Epoch [7/30], Loss: 1.0738\n",
      "Epoch [8/30] Batch 0, Loss: 1.0040\n",
      "Epoch [8/30] Batch 10, Loss: 0.9301\n",
      "Epoch [8/30] Batch 20, Loss: 0.9693\n",
      "Epoch [8/30] Batch 30, Loss: 0.9174\n",
      "Epoch [8/30] Batch 40, Loss: 0.9398\n",
      "Epoch [8/30], Loss: 1.1626\n",
      "Epoch [9/30] Batch 0, Loss: 0.9845\n",
      "Epoch [9/30] Batch 10, Loss: 0.9318\n",
      "Epoch [9/30] Batch 20, Loss: 0.9599\n",
      "Epoch [9/30] Batch 30, Loss: 0.9784\n",
      "Epoch [9/30] Batch 40, Loss: 0.7898\n",
      "Epoch [9/30], Loss: 0.9771\n",
      "Epoch [10/30] Batch 0, Loss: 1.0663\n",
      "Epoch [10/30] Batch 10, Loss: 0.8825\n",
      "Epoch [10/30] Batch 20, Loss: 0.8310\n",
      "Epoch [10/30] Batch 30, Loss: 0.8613\n",
      "Epoch [10/30] Batch 40, Loss: 0.9340\n",
      "Epoch [10/30], Loss: 0.9048\n",
      "Epoch [11/30] Batch 0, Loss: 0.9434\n",
      "Epoch [11/30] Batch 10, Loss: 0.8473\n",
      "Epoch [11/30] Batch 20, Loss: 0.7648\n",
      "Epoch [11/30] Batch 30, Loss: 0.8829\n",
      "Epoch [11/30] Batch 40, Loss: 0.8525\n",
      "Epoch [11/30], Loss: 0.7381\n",
      "Epoch [12/30] Batch 0, Loss: 0.6373\n",
      "Epoch [12/30] Batch 10, Loss: 0.8264\n",
      "Epoch [12/30] Batch 20, Loss: 0.8620\n",
      "Epoch [12/30] Batch 30, Loss: 0.7913\n",
      "Epoch [12/30] Batch 40, Loss: 0.6463\n",
      "Epoch [12/30], Loss: 0.7935\n",
      "Epoch [13/30] Batch 0, Loss: 0.6783\n",
      "Epoch [13/30] Batch 10, Loss: 0.7115\n",
      "Epoch [13/30] Batch 20, Loss: 0.6735\n",
      "Epoch [13/30] Batch 30, Loss: 0.8351\n",
      "Epoch [13/30] Batch 40, Loss: 0.6749\n",
      "Epoch [13/30], Loss: 0.5927\n",
      "Epoch [14/30] Batch 0, Loss: 0.6812\n",
      "Epoch [14/30] Batch 10, Loss: 0.8286\n",
      "Epoch [14/30] Batch 20, Loss: 0.6380\n",
      "Epoch [14/30] Batch 30, Loss: 0.6349\n",
      "Epoch [14/30] Batch 40, Loss: 0.5543\n",
      "Epoch [14/30], Loss: 0.5750\n",
      "Epoch [15/30] Batch 0, Loss: 0.5422\n",
      "Epoch [15/30] Batch 10, Loss: 0.5426\n",
      "Epoch [15/30] Batch 20, Loss: 0.5033\n",
      "Epoch [15/30] Batch 30, Loss: 0.5424\n",
      "Epoch [15/30] Batch 40, Loss: 0.7613\n",
      "Epoch [15/30], Loss: 0.5819\n",
      "Epoch [16/30] Batch 0, Loss: 0.4209\n",
      "Epoch [16/30] Batch 10, Loss: 0.4695\n",
      "Epoch [16/30] Batch 20, Loss: 0.4309\n",
      "Epoch [16/30] Batch 30, Loss: 0.3525\n",
      "Epoch [16/30] Batch 40, Loss: 0.4931\n",
      "Epoch [16/30], Loss: 0.5117\n",
      "Epoch [17/30] Batch 0, Loss: 0.4983\n",
      "Epoch [17/30] Batch 10, Loss: 0.3948\n",
      "Epoch [17/30] Batch 20, Loss: 0.6884\n",
      "Epoch [17/30] Batch 30, Loss: 0.4401\n",
      "Epoch [17/30] Batch 40, Loss: 0.3945\n",
      "Epoch [17/30], Loss: 0.4696\n",
      "Epoch [18/30] Batch 0, Loss: 0.3563\n",
      "Epoch [18/30] Batch 10, Loss: 0.3478\n",
      "Epoch [18/30] Batch 20, Loss: 0.3950\n",
      "Epoch [18/30] Batch 30, Loss: 0.3938\n",
      "Epoch [18/30] Batch 40, Loss: 0.3758\n",
      "Epoch [18/30], Loss: 0.4442\n",
      "Epoch [19/30] Batch 0, Loss: 0.3834\n",
      "Epoch [19/30] Batch 10, Loss: 0.4429\n",
      "Epoch [19/30] Batch 20, Loss: 0.3427\n",
      "Epoch [19/30] Batch 30, Loss: 0.2476\n",
      "Epoch [19/30] Batch 40, Loss: 0.2777\n",
      "Epoch [19/30], Loss: 0.3340\n",
      "Epoch [20/30] Batch 0, Loss: 0.2419\n",
      "Epoch [20/30] Batch 10, Loss: 0.3031\n",
      "Epoch [20/30] Batch 20, Loss: 0.2648\n",
      "Epoch [20/30] Batch 30, Loss: 0.3476\n",
      "Epoch [20/30] Batch 40, Loss: 0.2381\n",
      "Epoch [20/30], Loss: 0.2288\n",
      "Epoch [21/30] Batch 0, Loss: 0.1758\n",
      "Epoch [21/30] Batch 10, Loss: 0.1508\n",
      "Epoch [21/30] Batch 20, Loss: 0.2732\n",
      "Epoch [21/30] Batch 30, Loss: 0.2774\n",
      "Epoch [21/30] Batch 40, Loss: 0.2168\n",
      "Epoch [21/30], Loss: 0.2789\n",
      "Epoch [22/30] Batch 0, Loss: 0.1549\n",
      "Epoch [22/30] Batch 10, Loss: 0.1552\n",
      "Epoch [22/30] Batch 20, Loss: 0.1071\n",
      "Epoch [22/30] Batch 30, Loss: 0.1440\n",
      "Epoch [22/30] Batch 40, Loss: 0.0766\n",
      "Epoch [22/30], Loss: 0.1490\n",
      "Epoch [23/30] Batch 0, Loss: 0.0711\n",
      "Epoch [23/30] Batch 10, Loss: 0.0948\n",
      "Epoch [23/30] Batch 20, Loss: 0.2945\n",
      "Epoch [23/30] Batch 30, Loss: 0.0998\n",
      "Epoch [23/30] Batch 40, Loss: 0.1127\n",
      "Epoch [23/30], Loss: 0.2279\n",
      "Epoch [24/30] Batch 0, Loss: 0.1195\n",
      "Epoch [24/30] Batch 10, Loss: 0.1046\n",
      "Epoch [24/30] Batch 20, Loss: 0.1473\n",
      "Epoch [24/30] Batch 30, Loss: 0.0943\n",
      "Epoch [24/30] Batch 40, Loss: 0.2092\n",
      "Epoch [24/30], Loss: 0.2987\n",
      "Epoch [25/30] Batch 0, Loss: 0.1435\n",
      "Epoch [25/30] Batch 10, Loss: 0.0819\n",
      "Epoch [25/30] Batch 20, Loss: 0.1154\n",
      "Epoch [25/30] Batch 30, Loss: 0.0623\n",
      "Epoch [25/30] Batch 40, Loss: 0.0586\n",
      "Epoch [25/30], Loss: 0.1069\n",
      "Epoch [26/30] Batch 0, Loss: 0.1343\n",
      "Epoch [26/30] Batch 10, Loss: 0.0351\n",
      "Epoch [26/30] Batch 20, Loss: 0.0793\n",
      "Epoch [26/30] Batch 30, Loss: 0.1527\n",
      "Epoch [26/30] Batch 40, Loss: 0.0731\n",
      "Epoch [26/30], Loss: 0.1080\n",
      "Epoch [27/30] Batch 0, Loss: 0.0499\n",
      "Epoch [27/30] Batch 10, Loss: 0.0416\n",
      "Epoch [27/30] Batch 20, Loss: 0.0294\n",
      "Epoch [27/30] Batch 30, Loss: 0.0777\n",
      "Epoch [27/30] Batch 40, Loss: 0.0700\n",
      "Epoch [27/30], Loss: 0.0340\n",
      "Epoch [28/30] Batch 0, Loss: 0.1188\n",
      "Epoch [28/30] Batch 10, Loss: 0.1057\n",
      "Epoch [28/30] Batch 20, Loss: 0.0181\n",
      "Epoch [28/30] Batch 30, Loss: 0.1069\n",
      "Epoch [28/30] Batch 40, Loss: 0.0600\n",
      "Epoch [28/30], Loss: 0.0686\n",
      "Epoch [29/30] Batch 0, Loss: 0.0326\n",
      "Epoch [29/30] Batch 10, Loss: 0.0326\n",
      "Epoch [29/30] Batch 20, Loss: 0.0502\n",
      "Epoch [29/30] Batch 30, Loss: 0.0099\n",
      "Epoch [29/30] Batch 40, Loss: 0.0192\n",
      "Epoch [29/30], Loss: 0.0303\n",
      "Epoch [30/30] Batch 0, Loss: 0.0141\n",
      "Epoch [30/30] Batch 10, Loss: 0.0237\n",
      "Epoch [30/30] Batch 20, Loss: 0.0186\n",
      "Epoch [30/30] Batch 30, Loss: 0.0472\n",
      "Epoch [30/30] Batch 40, Loss: 0.0446\n",
      "Epoch [30/30], Loss: 0.1006\n"
     ]
    }
   ],
   "source": [
    "model = myCNN()\n",
    "\n",
    "# define everything needed for training\n",
    "n_epochs = 30\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# execute trainingmplement a small MLP that takes an output of the pretrained model as input, with\n",
    "2 output nodes. The ML\n",
    "train(model, n_epochs, optim, criterion, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'mycnn.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 7 [0.5 point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T18:11:04.611975Z",
     "start_time": "2025-03-22T18:10:59.192006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy for class ’berry’: 73.44% \n",
      " Accuracy for class ’bird’: 60.74% \n",
      " Accuracy for class ’dog’: 77.73% \n",
      " Accuracy for class ’flower’: 72.07% \n",
      " Accuracy for class ’other’: 67.03% \n"
     ]
    }
   ],
   "source": [
    "def accuracy(model, testloader):\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # initialise correct and total counts per class\n",
    "    correct = {n: 0 for n in range(5)}\n",
    "    total = {n: 0 for n in range(5)}\n",
    "\n",
    "    # set model to evaluate mode\n",
    "    model.to(device).eval()\n",
    "\n",
    "    # no gradient context\n",
    "    with torch.no_grad():\n",
    "        # iterate test loader\n",
    "        for inputs, labels in testloader:\n",
    "            # process inputs\n",
    "            output = model(inputs.to(device))\n",
    "            # reduce logits with argmax to find output class\n",
    "            output_argmax = torch.argmax(output, dim=-1).cpu()\n",
    "\n",
    "            # process outputs per class\n",
    "            for u in torch.unique(labels):\n",
    "                # find indexes for current class\n",
    "                idxs = labels == output_argmax\n",
    "                # calculate number of correct classes\n",
    "                correct_for_class = torch.sum(labels[idxs] == output_argmax[idxs]).item()\n",
    "                # update correct count for class\n",
    "                correct[u.item()] += correct_for_class\n",
    "                # update total count for class\n",
    "                total[u.item()] += labels.shape[0]\n",
    "\n",
    "    c = testloader.dataset.class_to_idx\n",
    "    # iterate classes\n",
    "    for class_name in testloader.dataset.classes:\n",
    "        # print accuracy using dictionaries (correct / total)\n",
    "        print (f\" Accuracy for class ’{class_name}’: {correct[c[class_name]] / total[c[class_name]] * 100:.2f}% \")\n",
    "\n",
    "# load state dict\n",
    "cnn = myCNN()\n",
    "cnn.load_state_dict(torch.load('mycnn.pth', weights_only=True))\n",
    "cnn.eval()\n",
    "\n",
    "# run accuracy function\n",
    "accuracy(cnn, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Part 2: Fine-tuning a pretrained model [3.5 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 [0.5 point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T18:10:28.326320Z",
     "start_time": "2025-03-22T18:10:28.316118Z"
    }
   },
   "outputs": [],
   "source": [
    "# same as first train and test loading but for smaller dataset\n",
    "\n",
    "transform_small = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size_small = 128\n",
    "\n",
    "# trainset_small = torchvision.datasets.ImageFolder(root=\"Linnaeus_5_32X32_small\\\\train\", transform=transform)\n",
    "trainset_small = torchvision.datasets.ImageFolder(root=\"Linnaeus_5_32X32_small/train\", transform=transform_small)\n",
    "\n",
    "trainloader_small = torch.utils.data.DataLoader(trainset_small, batch_size=batch_size_small, shuffle=True)\n",
    "\n",
    "# testset_small = torchvision.datasets.ImageFolder(root=\"Linnaeus_5_32X32_small\\\\test\", transform=transform)\n",
    "testset_small = torchvision.datasets.ImageFolder(root=\"Linnaeus_5_32X32_small/test\", transform=transform_small)\n",
    "\n",
    "testloader_small = torch.utils.data.DataLoader(testset_small, batch_size=batch_size_small, shuffle=False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 2 [1 point]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogSoftmax: Converts the raw logits (i.e. the unbounded output of the final linear layer) into log probabilities. This step is critical because:\n",
    "\n",
    "It ensures numerical stability.\n",
    "It provides inputs in the form that NLLLoss expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T18:10:32.364656Z",
     "start_time": "2025-03-22T18:10:32.360343Z"
    }
   },
   "outputs": [],
   "source": [
    "class myMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myMLP, self).__init__()\n",
    "        # fully connected layers 5 -> 128 -> 128 -> 2\n",
    "        self.fc1 = nn.Linear(5, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 2)\n",
    "\n",
    "        # relu activation\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # logsoftmax output\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.logsoftmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Determine and justify the number of input nodes for the MLP.\n",
    "\n",
    "We are using the MLP to process the output of the CNN. The CNN has 5 output logits and therefore this must be the number of input nodes to the MLP.\n",
    "\n",
    "#### 2. We are going to use the negative log likelihood loss for training later, with criterion torch.nn.NLLLoss(). Based on the lecture notes and the PyTorch documentation, find and explain what nonlinear function should we use at the output layer of the MLP. Also explain why this loss function is an appropriate choice for this task.\n",
    "\n",
    "Based on the use of NLLLoss, it is logical to use LogSoftmax as our nonlinear function. The pytorch documentation for NLLLoss indicate that it expects log probabilities to compute the negative log likelihood. LogSoftmax converts the raw logits into their log probabilities which is exactly as required. The combination of NLLLoss and LogSoftmax benefits from better numerical stability compared to alternatives such as just Softmax. Numerically it is also equivalent to using CrossEntropyLoss which uses LogSoftmax internally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T12:36:28.113931Z",
     "start_time": "2025-03-22T12:36:28.088704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 128]             768\n",
      "              ReLU-2                  [-1, 128]               0\n",
      "            Linear-3                  [-1, 128]          16,512\n",
      "              ReLU-4                  [-1, 128]               0\n",
      "            Linear-5                    [-1, 2]             258\n",
      "        LogSoftmax-6                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 17,538\n",
      "Trainable params: 17,538\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.07\n",
      "Estimated Total Size (MB): 0.07\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(myMLP().cuda(), input_size=(5,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 3 [0.5 point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T18:10:34.879005Z",
     "start_time": "2025-03-22T18:10:34.875169Z"
    }
   },
   "outputs": [],
   "source": [
    "def fine_tune(myCNN, myMLP, nr_epochs, optimizer, criterion, trainloader):\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    myMLP.to(device)\n",
    "    myCNN.to(device)\n",
    "    batch_size = trainloader.batch_size\n",
    "    \n",
    "    criterion.to(device)\n",
    "\n",
    "    # freeze cnn\n",
    "    for param in myCNN.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # loop for number of epochs\n",
    "    for epoch in range(nr_epochs):\n",
    "        # iterate training loader\n",
    "        for i, (inputs, labels) in enumerate(trainloader):\n",
    "            # zero gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # move inputs and labels to device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # get cnn output\n",
    "            features = myCNN(inputs)\n",
    "            # run cnn output through mlp\n",
    "            outputs = myMLP(features)\n",
    "\n",
    "            # calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # back propagate\n",
    "            loss.backward()\n",
    "\n",
    "            # move back to cpu to save gpu memory\n",
    "            inputs = inputs.cpu()\n",
    "            labels = labels.cpu()\n",
    "\n",
    "            # parameter step\n",
    "            optimizer.step()\n",
    "\n",
    "            # output every 10 batches\n",
    "            if i % 10 == 0:\n",
    "                print('Epoch [{}/{}], Batch {}, Loss: {:.8f}'.format(epoch, nr_epochs, i, loss.item()))\n",
    "\n",
    "        # print epoch loss\n",
    "        print('Epoch [{}/{}], Loss: {:.8f}'.format(epoch, nr_epochs, loss.item()))\n",
    "\n",
    "    myMLP.cpu()\n",
    "    myCNN.cpu()\n",
    "    criterion.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 4 [0.5 point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T23:13:45.535415600Z",
     "start_time": "2025-03-17T20:51:47.420639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/30], Batch 0, Loss: 0.89327699\n",
      "Epoch [0/30], Batch 10, Loss: 0.01395314\n",
      "Epoch [0/30], Loss: 0.00170322\n",
      "Epoch [1/30], Batch 0, Loss: 0.00123168\n",
      "Epoch [1/30], Batch 10, Loss: 0.00090814\n",
      "Epoch [1/30], Loss: 0.00008038\n",
      "Epoch [2/30], Batch 0, Loss: 0.00022462\n",
      "Epoch [2/30], Batch 10, Loss: 0.00006717\n",
      "Epoch [2/30], Loss: 0.00053189\n",
      "Epoch [3/30], Batch 0, Loss: 0.00227133\n",
      "Epoch [3/30], Batch 10, Loss: 0.00028253\n",
      "Epoch [3/30], Loss: 0.00007222\n",
      "Epoch [4/30], Batch 0, Loss: 0.00109872\n",
      "Epoch [4/30], Batch 10, Loss: 0.00004144\n",
      "Epoch [4/30], Loss: 0.00006138\n",
      "Epoch [5/30], Batch 0, Loss: 0.00068104\n",
      "Epoch [5/30], Batch 10, Loss: 0.00032267\n",
      "Epoch [5/30], Loss: 0.00013212\n",
      "Epoch [6/30], Batch 0, Loss: 0.00000945\n",
      "Epoch [6/30], Batch 10, Loss: 0.00007837\n",
      "Epoch [6/30], Loss: 0.00175043\n",
      "Epoch [7/30], Batch 0, Loss: 0.00131386\n",
      "Epoch [7/30], Batch 10, Loss: 0.00020252\n",
      "Epoch [7/30], Loss: 0.00011232\n",
      "Epoch [8/30], Batch 0, Loss: 0.00001311\n",
      "Epoch [8/30], Batch 10, Loss: 0.00000779\n",
      "Epoch [8/30], Loss: 0.00001366\n",
      "Epoch [9/30], Batch 0, Loss: 0.00001020\n",
      "Epoch [9/30], Batch 10, Loss: 0.00000257\n",
      "Epoch [9/30], Loss: 0.00006112\n",
      "Epoch [10/30], Batch 0, Loss: 0.00001103\n",
      "Epoch [10/30], Batch 10, Loss: 0.00086461\n",
      "Epoch [10/30], Loss: 0.00000917\n",
      "Epoch [11/30], Batch 0, Loss: 0.00034431\n",
      "Epoch [11/30], Batch 10, Loss: 0.00001100\n",
      "Epoch [11/30], Loss: 0.00001971\n",
      "Epoch [12/30], Batch 0, Loss: 0.00000623\n",
      "Epoch [12/30], Batch 10, Loss: 0.00000574\n",
      "Epoch [12/30], Loss: 0.00000401\n",
      "Epoch [13/30], Batch 0, Loss: 0.00098853\n",
      "Epoch [13/30], Batch 10, Loss: 0.00020736\n",
      "Epoch [13/30], Loss: 0.00001784\n",
      "Epoch [14/30], Batch 0, Loss: 0.00021363\n",
      "Epoch [14/30], Batch 10, Loss: 0.00000168\n",
      "Epoch [14/30], Loss: 0.00001046\n",
      "Epoch [15/30], Batch 0, Loss: 0.00001719\n",
      "Epoch [15/30], Batch 10, Loss: 0.00007847\n",
      "Epoch [15/30], Loss: 0.00000238\n",
      "Epoch [16/30], Batch 0, Loss: 0.00042603\n",
      "Epoch [16/30], Batch 10, Loss: 0.00000140\n",
      "Epoch [16/30], Loss: 0.00000059\n",
      "Epoch [17/30], Batch 0, Loss: 0.00021053\n",
      "Epoch [17/30], Batch 10, Loss: 0.00000189\n",
      "Epoch [17/30], Loss: 0.00000084\n",
      "Epoch [18/30], Batch 0, Loss: 0.00000167\n",
      "Epoch [18/30], Batch 10, Loss: 0.00031694\n",
      "Epoch [18/30], Loss: 0.00000027\n",
      "Epoch [19/30], Batch 0, Loss: 0.00009052\n",
      "Epoch [19/30], Batch 10, Loss: 0.00000189\n",
      "Epoch [19/30], Loss: 0.00000010\n",
      "Epoch [20/30], Batch 0, Loss: 0.00000388\n",
      "Epoch [20/30], Batch 10, Loss: 0.00004542\n",
      "Epoch [20/30], Loss: 0.00001034\n",
      "Epoch [21/30], Batch 0, Loss: 0.00000319\n",
      "Epoch [21/30], Batch 10, Loss: 0.00000123\n",
      "Epoch [21/30], Loss: 0.00000534\n",
      "Epoch [22/30], Batch 0, Loss: 0.00006193\n",
      "Epoch [22/30], Batch 10, Loss: 0.00022437\n",
      "Epoch [22/30], Loss: 0.00000115\n",
      "Epoch [23/30], Batch 0, Loss: 0.00000438\n",
      "Epoch [23/30], Batch 10, Loss: 0.00006184\n",
      "Epoch [23/30], Loss: 0.00031283\n",
      "Epoch [24/30], Batch 0, Loss: 0.00000087\n",
      "Epoch [24/30], Batch 10, Loss: 0.00000023\n",
      "Epoch [24/30], Loss: 0.00000027\n",
      "Epoch [25/30], Batch 0, Loss: 0.00000182\n",
      "Epoch [25/30], Batch 10, Loss: 0.00000041\n",
      "Epoch [25/30], Loss: 0.00000041\n",
      "Epoch [26/30], Batch 0, Loss: 0.00000012\n",
      "Epoch [26/30], Batch 10, Loss: 0.00000219\n",
      "Epoch [26/30], Loss: 0.00000066\n",
      "Epoch [27/30], Batch 0, Loss: 0.00000562\n",
      "Epoch [27/30], Batch 10, Loss: 0.00000018\n",
      "Epoch [27/30], Loss: 0.00000585\n",
      "Epoch [28/30], Batch 0, Loss: 0.00002916\n",
      "Epoch [28/30], Batch 10, Loss: 0.00000014\n",
      "Epoch [28/30], Loss: 0.00000008\n",
      "Epoch [29/30], Batch 0, Loss: 0.00000169\n",
      "Epoch [29/30], Batch 10, Loss: 0.00000336\n",
      "Epoch [29/30], Loss: 0.00000004\n"
     ]
    }
   ],
   "source": [
    "# load cnn\n",
    "cnn = myCNN()\n",
    "cnn.load_state_dict(torch.load('mycnn.pth', weights_only=True))\n",
    "cnn.eval()\n",
    "\n",
    "# initialise mlp\n",
    "mlp = myMLP()\n",
    "\n",
    "# other things needed for training\n",
    "n_epochs = 30\n",
    "optim = torch.optim.Adam(mlp.parameters(), lr=0.001)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# fine tune\n",
    "fine_tune(cnn, mlp, n_epochs, optim, criterion, trainloader_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mlp.state_dict(), 'mymlp1.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 5 [1 point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T18:11:10.072808Z",
     "start_time": "2025-03-22T18:11:09.653957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy for class ’dog’: 95.70%\n",
      " Accuracy for class ’flower’: 96.39%\n"
     ]
    }
   ],
   "source": [
    "def accuracy_fine_tune(myCNN, myMLP, testloader_small):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    myMLP.to(device).eval()\n",
    "    myCNN.to(device).eval()\n",
    "\n",
    "    # correct and total dictionaries per \n",
    "    correct = {n: 0 for n in range(2)}\n",
    "    total = {n: 0 for n in range(2)}\n",
    "\n",
    "    # to gradient context\n",
    "    with torch.no_grad():\n",
    "        # iterate test loader\n",
    "        for inputs, labels in testloader_small:\n",
    "            # move inputs to device and process through cnn and mlp and exponentiate to get probabilities\n",
    "            features = myCNN(inputs.to(device))\n",
    "            outputs = torch.exp(myMLP(features))\n",
    "\n",
    "            # argmax to get reduce probabilities to output\n",
    "            output_argmax = torch.argmax(outputs, dim=-1).cpu()\n",
    "\n",
    "            # iterate classes\n",
    "            for u in torch.unique(labels):\n",
    "                # get indexes for class\n",
    "                idxs = labels == output_argmax\n",
    "                # calculate number of correct\n",
    "                correct_for_class = torch.sum(labels[idxs] == output_argmax[idxs]).item()\n",
    "                # update correct count\n",
    "                correct[u.item()] += correct_for_class\n",
    "                # update total count\n",
    "                total[u.item()] += labels.shape[0]\n",
    "\n",
    "    c = testloader_small.dataset.class_to_idx\n",
    "    # Print the accuracy for each class\n",
    "    for class_name in testloader_small.dataset.classes :\n",
    "        print (f\" Accuracy for class ’{class_name}’: {correct[c[class_name]] / total[c[class_name]] * 100:.2f}%\")\n",
    "\n",
    "# load both models\n",
    "cnn = myCNN()\n",
    "cnn.load_state_dict(torch.load('mycnn.pth', weights_only=True))\n",
    "cnn.eval()\n",
    "\n",
    "mlp = myMLP()\n",
    "mlp.load_state_dict(torch.load('mymlp1.pth', weights_only=True))\n",
    "mlp.eval()\n",
    "\n",
    "# accuracy function\n",
    "accuracy_fine_tune(cnn, mlp, testloader_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment on the results and compare the accuracy of the fine-tuned model with the accuracy of the CNN model from Part 1.\n",
    "\n",
    "- The CNN achieved class accuracies ranging from 61% to 78%. In contrast, the fine tuned model with the MLP reached above 95% accuracy on both classes it was trained on.\n",
    "\n",
    "- This is not a surprising result as we reduced the complexity of the task my removing 3 of 5 categories, reducing the problem to only a binary classification. This makes it inherently easier for the model to distinguish between the two remaining classes due to simpler decision boundaries. \n",
    "\n",
    "- The original model's fully connected layers were tasked with identifying 5 different classes. By adding more 'post-processing' parameters in the form of the MLP to classify from extracted features, thereby giving the model more capacity to learn and resulting in high accuracies.\n",
    "\n",
    "- It is evident that the CNN on its own struggled to generalise well on its more challenging dataset. The greatly improved accuracies with the fine tuning indicate that the feed forward layers of the CNN were inadequate for the scale of the original task. On the other hand, the feature extraction layers of the CNN were useful in the fine tuning and show that they learnt well.\n",
    "\n",
    "- Training the CNN's feature extraction layers on a broader dataset was probably beneficial as it was exposed to a richer set of features, shapes and objects, therefore feeding the fine-tuned MLP better extracted features than if the CNN was only trained on the two dog and flower classes.\n",
    "\n",
    "- The CNN started at a high loss and steadily decreased over the epochs, showing some variability with occasional increases and decreases. This reflects the complexity of it's original task and show how the feed forward layers int the original model were struggling. In contrast, the loss for the fine tuned MLP drops rapidly to near 0, indicating that the binary classification problem was learned very quickly, meaning a larger feed forward classifier was easily able to capture the differences between only two classes.\n",
    "\n",
    "- We might have has concerns about overfitting given the training loss of the MLP being near zero, however the test accuracies show us that this the model generalised well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Part 3: Adversarial attacks [4.5 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 1 [1 point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T18:17:01.788869Z",
     "start_time": "2025-03-22T18:17:01.780168Z"
    }
   },
   "outputs": [],
   "source": [
    "def adversarial(myCNN, myMLP, image, label, epsilon=0.01):\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # move models to device\n",
    "    myCNN.to(device)\n",
    "    myMLP.to(device)\n",
    "\n",
    "    # make a clone of the image and move it to device\n",
    "    image = image.clone().to(device)\n",
    "\n",
    "    # set models to evaluation mode\n",
    "    myCNN.eval()\n",
    "    myMLP.eval()\n",
    "\n",
    "    # NLLLoss function\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    # hyperparameters\n",
    "    nr_steps = 10\n",
    "    mu = 1.0\n",
    "    alpha = epsilon / nr_steps\n",
    "\n",
    "    # momentum term\n",
    "    g = torch.zeros_like(image, device=device)\n",
    "\n",
    "    # we will use x in the loop. enable gradient tracking\n",
    "    x = image.detach().requires_grad_()\n",
    "    x.to(device)\n",
    "\n",
    "    # format label as tensor\n",
    "    lbl = torch.as_tensor(label, device=device).unsqueeze(0).long().to(device)\n",
    "\n",
    "    # Loop over the number of steps and update the image\n",
    "    for i in range(nr_steps):\n",
    "        # zero gradients\n",
    "        myCNN.zero_grad()\n",
    "        myMLP.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        output = myCNN(x.unsqueeze(0))\n",
    "        output = myMLP(output)\n",
    "\n",
    "        # compute loss\n",
    "        loss = criterion(output, lbl)\n",
    "\n",
    "        # backpropagate with respect to x\n",
    "        loss.backward()\n",
    "        grad = x.grad\n",
    "\n",
    "        # update momentum with L1-norm normalization\n",
    "        grad_norm = torch.norm(grad, p=1) + 1e-8  # avoid div-by-zero\n",
    "        g = mu * g + grad / grad_norm\n",
    "\n",
    "        # parameter step with sign of momentum\n",
    "        x = x + alpha * torch.sign(g)\n",
    "\n",
    "        # reset gradients on x\n",
    "        x = x.detach().requires_grad_()\n",
    "\n",
    "    # final adversarial image\n",
    "    adv_image = x.detach()\n",
    "    adv_image_cpu = adv_image.cpu()\n",
    "\n",
    "    # get probability of adversarial image\n",
    "    output = myCNN(adv_image.unsqueeze(0))\n",
    "    output = myMLP(output)\n",
    "    p = torch.exp(output)[0, label].item()\n",
    "\n",
    "    return adv_image_cpu, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Question 2 [1 point]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explain the role of the parameter epsilon in the function and how the algorithm is working.\n",
    "\n",
    "Epsilon ($\\epsilon$) is the 'size of the perturbation'. Intuitively it defines a search space around x, the maximum allowed change under the $L_\\infty$ norm, in which to find an adversarial example. The idea is that within this small $\\epsilon$-radius of our starting image, we can find a similar adversarial image which gives us a different output from the classifier and this adversarial example is at most '$\\epsilon$ far' from the original image. Higher epsilons have higher success rates in finding an adversarial example but at the cost of imperceptibility (i.e. the adverse example will be more different to the original).\n",
    "\n",
    "The algorithm starts by initialising the following variables. $\\alpha = \\frac{\\epsilon}{T}$, where T is the number of iterations, is set as a step size such that even if we travel in the same direction T times, we are at most $\\epsilon$ from the starting image and ensuring we stay within the $\\epsilon-L_\\infty$ ball. $g_0=0$ initialises our momentum variable to 0. And $x^*_0=x$ begins our search for the adversarial image at the original image.\n",
    "\n",
    "The algorithm loops for $0 \\leq t \\leq T-1$:\n",
    "- In each iteration it classifies the current image $x^*_t$ and computes the gradient of the loss function (in our case NLLLoss) with respect to $x^*_t$.\n",
    "- This gradient ($grad$) is then used to update the momentum variable as follows: $g_{t+1} = \\mu \\cdot g_t + \\frac{grad}{\\| grad \\|_1}$. The previous momentum is multiplied by a decay variable $\\mu$ and the newest normalised gradient is added. The decay variable determines how strongly the momentum rememberes gradients from far in the past. By building this momentum, the algorithm can better navigate the loss landscape, i.e. noisy or oscillating gradients, in search of the adversarial example.\n",
    "- Then the sign of the momentum $g_{t+1}$ is used to update the current image as follows: $x^*_{t+1} = x^*_t + \\alpha \\cdot \\text{sign}(g_{t+1})$. The effect of the momentum can be understood with a simple example, e.g. if there is lots of initial momentum in the positive direction and then a small amount in the negative direction, we can see how the momentum would likely still have positive sign. Therefore the algorithm would not react to the small negative gradient and continue the search in the positive direction.\n",
    "\n",
    "After T iterations, the current image is taken as the adversarial image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 3 [0.5 point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T18:25:29.394806Z",
     "start_time": "2025-03-22T18:25:29.193971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004589585878420621"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick image from test dataset\n",
    "im, l = testset_small[6]\n",
    "# get adversarial image\n",
    "adv, p = adversarial(cnn, mlp, im, l, epsilon=0.05)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# same rescale function but with a clamp\n",
    "def rescale(img):\n",
    "    return (torch.clamp(img, -1, 1) + 1) / 2\n",
    "\n",
    "# reformat images\n",
    "im_ = rescale(im).detach().numpy().transpose(1, 2, 0)\n",
    "adv_ = rescale(adv).detach().numpy().transpose(1, 2, 0)\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(im_)\n",
    "ax[1].imshow(adv_)\n",
    "ax[0].set_title(\"original\")\n",
    "ax[1].set_title(f\"adversarial p={p:.6f}\")\n",
    "ax[0].axis('off')\n",
    "ax[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 4 [0.5 point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate at epsilon=0.05: 0.67708\n"
     ]
    }
   ],
   "source": [
    "def accuracy_adversarial(myCNN, myMLP, testloader_small, epsilon):\n",
    "    total_correct = 0\n",
    "    total_attacked = 0\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    myCNN = myCNN.to(device)\n",
    "    myMLP = myMLP.to(device)\n",
    "\n",
    "    # iterate test loader\n",
    "    for data in testloader_small:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # evaluate images\n",
    "        outputs = myCNN.forward(images)\n",
    "        outputs = torch.exp(myMLP(outputs))\n",
    "        output_argmax = torch.argmax(outputs, dim=-1)\n",
    "        # get correct indexes\n",
    "        correct = (output_argmax == labels)\n",
    "\n",
    "        # loop over classified correctly iamges in batch\n",
    "        for im, lbl in zip(images[correct], labels[correct]):\n",
    "            # update correct count\n",
    "            total_correct += 1\n",
    "            # generate an adversarial example\n",
    "            adv, p = adversarial(myCNN, myMLP, im, lbl, epsilon)\n",
    "            # check if the attack was successful\n",
    "            if p < 0.5:\n",
    "                total_attacked += 1\n",
    "\n",
    "    return total_attacked / total_correct\n",
    "    \n",
    "success_rate = accuracy_adversarial(cnn, mlp, testloader_small, 0.05)\n",
    "print(f'Success rate at epsilon=0.05: {success_rate:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 5 [1 point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T18:28:40.326921Z",
     "start_time": "2025-03-22T18:27:20.721128Z"
    }
   },
   "outputs": [],
   "source": [
    "# defined epsilons\n",
    "es = [0.02, 0.04, 0.06, 0.08, 0.1]\n",
    "# run adversarial accuracy for each epsilon\n",
    "adv_success_rates = [accuracy_adversarial(cnn, mlp, testloader_small, e) for e in es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(0.02, 0.2545454545454545),\n",
       " (0.04, 0.5545454545454546),\n",
       " (0.06, 0.7207792207792207),\n",
       " (0.08, 0.7974025974025974),\n",
       " (0.1, 0.8428571428571429)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot success rates over epsilons\n",
    "plt.plot(es, adv_success_rates, marker='X')\n",
    "plt.xlabel('epsilon')\n",
    "plt.ylabel('adversarial success rate')\n",
    "plt.show()\n",
    "\n",
    "# show epsilon and success rate pairs\n",
    "list(zip(es, adv_success_rates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### comment on results\n",
    "\n",
    "The trend is that the success rate of finding an adversarial image grows with $\\epsilon$. From $\\epsilon=0.02$ to $0.06$, there is quite a sharp increase from 25% to 72%, after which it plateaus to 84% at $\\epsilon=0.1$.\n",
    "\n",
    "This outcome is expected. As explained in the description of the algorithm, $\\epsilon$ defines the $L_\\infty$ ball around the original image (pixel-wise) in which we can search for an adversarial example. Higher epsilon will naturally result in higher success rate due to the fact we have a wider search radius and we can stray further from the original in search of an image that the classifier thinks is different. However, if we compared successful examples at $\\epsilon=1$ and $\\epsilon=0.05$ to the original, the $\\epsilon=0.05$ example would likely be more similar and be considered a better adversarial example as it was able to fool the classifier with less changes to the input.\n",
    "\n",
    "The rapid increase at smaller epsilons indicate that the model is robust at these small epsilons but quickly becomes vulnerable to attack as epsilon grows. The plateauing curve shows diminishing returns past $\\epsilon=0.1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 6 [0.5 point]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment on the impact of adversarial attacks in real-world applications and discuss possible ways to mitigate them. (Machine learning researchers are usually required to include a broader impact statement in their papers about potential consequences of their work, which is why I’m including this question)\n",
    "\n",
    "Adversarial attacks can have an impact anywhere that machine learning models are deployed in the real world, especially in security and privacy sentitive settings. E.g.: \n",
    "- Autonomous vehicles may not decide to brake at the sight due to the mis-classification of a human or obstacle on the road in the object detection software.\n",
    "- Medical diagnosis software used to scan MRIs and X-rays. A segmentation model can fail to identify a tumor or hairline fracture in an image and thereby resulting in a critital mis-diagnosis of the patient.\n",
    "- Biometric authentication systems must be absolutely robust to small perturbations in input fingerprint/facial scan so as to not allow for unauthorised access.\n",
    "\n",
    "Each of the above examples could have widespread and detremental impact if the adversarial attacks are not properly accounted for in the deployment of these ml models. Therefore it is essential that these developers investivate the robustness of their models.\n",
    "\n",
    "There are many ways of mitigating these adversarial attacks: E.g.:\n",
    "- Training/tuning models on adversarially collected images. This method allows the model to learn from its mistakes and define better decision boundaries between classes, becoming more robust against small perturbations in its input. This method might take time and effort to collect enough examples and then fine tune the model.\n",
    "- Training with augmentation e.g. cropping, resizing, adding small amounts of noise, random colour scale adjustments. Used in the appropriate setting for images, e.g. our example above would have worked, augmentations work as a regularisation and makes the model more robust to small insignificant changes that it might have otherwise been fooled by. This method has close to no additional cost at training time and none at evaluation time. \n",
    "- Ensemble models. This method runs multiple trained versions of the model, usually in parallel, and combines them to create an output. E.g. out of 5 models, 4 classify the image as class 3 and 1 classifies as class 2, the overall vote would lean in favour of class 4. We can easily see how this would make it harder for adversarial examples to fool more than one model. You could also use ensemble models to run confidence checks and evaluating statistical significance of outcomes. However this comes at a large cost of not only storing but also running computation on all of these unique models.\n",
    "- Monte-carlo dropout. Models can be designed with dropout layers. Inference on the input can be run multiple times, each time giving the dropout layers a chance to regularise the model differently. We can therefore use this one model in the same way as the ensemble models described previously."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseenv",
   "language": "python",
   "name": "baseenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
